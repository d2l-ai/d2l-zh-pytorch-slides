# d2l-ai/d2l-zh-pytorch-slides

This repo contains generated notebook slides. To open it locally, we suggest you to install the [rise](https://rise.readthedocs.io/en/stable/) extension.

You can also preview them in nbviwer:
 - [chapter_preliminaries/ndarray.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_preliminaries/ndarray.ipynb)
 - [chapter_preliminaries/pandas.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_preliminaries/pandas.ipynb)
 - [chapter_preliminaries/linear-algebra.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_preliminaries/linear-algebra.ipynb)
 - [chapter_preliminaries/calculus.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_preliminaries/calculus.ipynb)
 - [chapter_preliminaries/autograd.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_preliminaries/autograd.ipynb)
 - [chapter_preliminaries/lookup-api.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_preliminaries/lookup-api.ipynb)
 - [chapter_linear-networks/linear-regression.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_linear-networks/linear-regression.ipynb)
 - [chapter_linear-networks/linear-regression-scratch.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_linear-networks/linear-regression-scratch.ipynb)
 - [chapter_linear-networks/linear-regression-concise.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_linear-networks/linear-regression-concise.ipynb)
 - [chapter_linear-networks/image-classification-dataset.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_linear-networks/image-classification-dataset.ipynb)
 - [chapter_linear-networks/softmax-regression-scratch.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_linear-networks/softmax-regression-scratch.ipynb)
 - [chapter_linear-networks/softmax-regression-concise.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_linear-networks/softmax-regression-concise.ipynb)
 - [chapter_multilayer-perceptrons/mlp.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_multilayer-perceptrons/mlp.ipynb)
 - [chapter_multilayer-perceptrons/mlp-scratch.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_multilayer-perceptrons/mlp-scratch.ipynb)
 - [chapter_multilayer-perceptrons/mlp-concise.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_multilayer-perceptrons/mlp-concise.ipynb)
 - [chapter_multilayer-perceptrons/underfit-overfit.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_multilayer-perceptrons/underfit-overfit.ipynb)
 - [chapter_multilayer-perceptrons/weight-decay.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_multilayer-perceptrons/weight-decay.ipynb)
 - [chapter_multilayer-perceptrons/dropout.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_multilayer-perceptrons/dropout.ipynb)
 - [chapter_multilayer-perceptrons/numerical-stability-and-init.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_multilayer-perceptrons/numerical-stability-and-init.ipynb)
 - [chapter_multilayer-perceptrons/kaggle-house-price.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_multilayer-perceptrons/kaggle-house-price.ipynb)
 - [chapter_deep-learning-computation/model-construction.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_deep-learning-computation/model-construction.ipynb)
 - [chapter_deep-learning-computation/parameters.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_deep-learning-computation/parameters.ipynb)
 - [chapter_deep-learning-computation/custom-layer.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_deep-learning-computation/custom-layer.ipynb)
 - [chapter_deep-learning-computation/read-write.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_deep-learning-computation/read-write.ipynb)
 - [chapter_deep-learning-computation/use-gpu.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_deep-learning-computation/use-gpu.ipynb)
 - [chapter_convolutional-neural-networks/conv-layer.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_convolutional-neural-networks/conv-layer.ipynb)
 - [chapter_convolutional-neural-networks/padding-and-strides.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_convolutional-neural-networks/padding-and-strides.ipynb)
 - [chapter_convolutional-neural-networks/channels.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_convolutional-neural-networks/channels.ipynb)
 - [chapter_convolutional-neural-networks/pooling.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_convolutional-neural-networks/pooling.ipynb)
 - [chapter_convolutional-neural-networks/lenet.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_convolutional-neural-networks/lenet.ipynb)
 - [chapter_convolutional-modern/alexnet.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_convolutional-modern/alexnet.ipynb)
 - [chapter_convolutional-modern/vgg.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_convolutional-modern/vgg.ipynb)
 - [chapter_convolutional-modern/nin.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_convolutional-modern/nin.ipynb)
 - [chapter_convolutional-modern/googlenet.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_convolutional-modern/googlenet.ipynb)
 - [chapter_convolutional-modern/batch-norm.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_convolutional-modern/batch-norm.ipynb)
 - [chapter_convolutional-modern/resnet.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_convolutional-modern/resnet.ipynb)
 - [chapter_convolutional-modern/densenet.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_convolutional-modern/densenet.ipynb)
 - [chapter_recurrent-neural-networks/sequence.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_recurrent-neural-networks/sequence.ipynb)
 - [chapter_recurrent-neural-networks/text-preprocessing.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_recurrent-neural-networks/text-preprocessing.ipynb)
 - [chapter_recurrent-neural-networks/language-models-and-dataset.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_recurrent-neural-networks/language-models-and-dataset.ipynb)
 - [chapter_recurrent-neural-networks/rnn-scratch.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_recurrent-neural-networks/rnn-scratch.ipynb)
 - [chapter_recurrent-neural-networks/rnn-concise.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_recurrent-neural-networks/rnn-concise.ipynb)
 - [chapter_recurrent-modern/gru.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_recurrent-modern/gru.ipynb)
 - [chapter_recurrent-modern/lstm.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_recurrent-modern/lstm.ipynb)
 - [chapter_recurrent-modern/deep-rnn.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_recurrent-modern/deep-rnn.ipynb)
 - [chapter_recurrent-modern/bi-rnn.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_recurrent-modern/bi-rnn.ipynb)
 - [chapter_recurrent-modern/machine-translation-and-dataset.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_recurrent-modern/machine-translation-and-dataset.ipynb)
 - [chapter_recurrent-modern/encoder-decoder.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_recurrent-modern/encoder-decoder.ipynb)
 - [chapter_recurrent-modern/seq2seq.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_recurrent-modern/seq2seq.ipynb)
 - [chapter_attention-mechanisms/nadaraya-waston.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_attention-mechanisms/nadaraya-waston.ipynb)
 - [chapter_attention-mechanisms/attention-scoring-functions.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_attention-mechanisms/attention-scoring-functions.ipynb)
 - [chapter_attention-mechanisms/bahdanau-attention.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_attention-mechanisms/bahdanau-attention.ipynb)
 - [chapter_attention-mechanisms/multihead-attention.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_attention-mechanisms/multihead-attention.ipynb)
 - [chapter_attention-mechanisms/self-attention-and-positional-encoding.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_attention-mechanisms/self-attention-and-positional-encoding.ipynb)
 - [chapter_attention-mechanisms/transformer.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_attention-mechanisms/transformer.ipynb)
 - [chapter_computational-performance/multiple-gpus.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_computational-performance/multiple-gpus.ipynb)
 - [chapter_computational-performance/multiple-gpus-concise.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_computational-performance/multiple-gpus-concise.ipynb)
 - [chapter_computer-vision/image-augmentation.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_computer-vision/image-augmentation.ipynb)
 - [chapter_computer-vision/fine-tuning.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_computer-vision/fine-tuning.ipynb)
 - [chapter_computer-vision/bounding-box.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_computer-vision/bounding-box.ipynb)
 - [chapter_computer-vision/anchor.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_computer-vision/anchor.ipynb)
 - [chapter_computer-vision/multiscale-object-detection.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_computer-vision/multiscale-object-detection.ipynb)
 - [chapter_computer-vision/object-detection-dataset.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_computer-vision/object-detection-dataset.ipynb)
 - [chapter_computer-vision/ssd.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_computer-vision/ssd.ipynb)
 - [chapter_computer-vision/semantic-segmentation-and-dataset.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_computer-vision/semantic-segmentation-and-dataset.ipynb)
 - [chapter_computer-vision/transposed-conv.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_computer-vision/transposed-conv.ipynb)
 - [chapter_computer-vision/fcn.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_computer-vision/fcn.ipynb)
 - [chapter_computer-vision/neural-style.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_computer-vision/neural-style.ipynb)
 - [chapter_computer-vision/kaggle-cifar10.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_computer-vision/kaggle-cifar10.ipynb)
 - [chapter_computer-vision/kaggle-dog.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_computer-vision/kaggle-dog.ipynb)
 - [chapter_natural-language-processing-applications/natural-language-inference-and-dataset.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_natural-language-processing-applications/natural-language-inference-and-dataset.ipynb)
 - [chapter_natural-language-processing-applications/natural-language-inference-bert.ipynb](https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/chapter_natural-language-processing-applications/natural-language-inference-bert.ipynb)